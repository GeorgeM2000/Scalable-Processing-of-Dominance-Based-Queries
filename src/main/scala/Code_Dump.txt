/*
    // Set up Spark configuration
    val conf = new SparkConf().setAppName("Skyline").setMaster("local")
    val sc = new SparkContext(conf)

    // Example usage:
    val points = sc.parallelize(Seq(
      Point(Array(1.0, 1.0)),
      Point(Array(2.0, 2.0)),
      Point(Array(3.0, 3.0)),
      Point(Array(0.5, 2.0)),
      Point(Array(4.0, 4.0)),
      Point(Array(5.0, 5.0)),
      Point(Array(6.0, 6.0)),
      Point(Array(0.2, 1.3)),
      Point(Array(8.0, 8.0)),
      Point(Array(9.0, 9.0))
    ))


    // Compute local skylines
    val localSkylines = points.mapPartitions(Skyline_Calculation.computeLocalSkyline).collect()

    // Compute global skylines
    val globalSkylines = Skyline_Calculation.computeGlobalSkyline(localSkylines.iterator)

    // Broadcast the Global Skyline Set to workers
    val globalSkylinesBroadcast = sc.broadcast(globalSkylines.toList)

    val results = points.mapPartitions { iter =>

      val localDominatedPoints = Skyline_Calculation.loadDominatedPointsFromLocalFileSystem()

      // Capture the global skyline iterator in the closure
      val globalSkylineIteratorOnWorker = globalSkylinesBroadcast.value

      for(s <- globalSkylineIteratorOnWorker) {
        for(d <- localDominatedPoints) {
          if(Skyline_Calculation.dominates(s, d)) {
            s.dominance_score += 1
          }
        }
      }

      globalSkylineIteratorOnWorker.iterator
    }


    results.foreach(println)

    // Print the top-k skyline points with the highest dominance score
    //val topK = 5 // Change this value to the desired top-k
    //val topKSkyline = globalDominanceScores.take(topK)

    //println(s"\nTop-$topK Skyline Points with Highest Dominance Score:")
    //topKSkyline.foreach(println)

    // Stop the SparkContext
    sc.stop()

     */

    /*
    val D = Iterator(
      Point(List(1.0, 1.0)),
      Point(List(2.0, 2.0)),
      Point(List(3.0, 3.0)),
      Point(List(0.5, 2.0)),
      Point(List(4.0, 4.0)),
      Point(List(5.0, 5.0)),
      Point(List(6.0, 6.0)),
      Point(List(0.2, 1.3)),
      Point(List(8.0, 8.0)),
      Point(List(9.0, 9.0))
    )

    val skylineSet = Skyline_Calculation.computeSkyline(D)
    println("Skyline Set:")
    skylineSet.foreach(println)

     */


         /*
             val D = Iterator(
               Point(Array(1.0, 1.0)),
               Point(Array(2.0, 2.0)),
               Point(Array(3.0, 3.0)),
               Point(Array(0.5, 2.0)),
               Point(Array(4.0, 4.0)),
               Point(Array(5.0, 5.0)),
               Point(Array(6.0, 6.0)),
               Point(Array(0.2, 0.9)),
               Point(Array(8.0, 8.0)),
               Point(Array(9.0, 9.0))
               //Point(Array(0.1, 0.1))
             )

              */

         val D = Iterator(
           Point(Array(1.0, 2.0)),
           Point(Array(1.5, 1.5)),
           Point(Array(2.5, 1.0)),
           Point(Array(1.25, 2.2)),
           Point(Array(1.25, 2.3)),
           Point(Array(1.6, 1.6)),
           Point(Array(1.6, 1.8)),
           Point(Array(2.6, 1.2)),
           Point(Array(2.15, 2.15)),
           Point(Array(2.20, 2.15)),
           Point(Array(2.10,2.40)),
           Point(Array(2.12,2.12)),
           Point(Array(3.15,2.25)),
           Point(Array(3.20,2.30))
         )

         val skylineSet = Skyline_Calculation.calculate(D)
         println("Skyline Set:")
         skylineSet.foreach(println)



  import scala.math._

  def createVariablePartitions(lines: Int, numberOfPartitions: Int): Vector[Vector[Int]] = {
    val partitionSize: Int = floor(lines.toDouble / numberOfPartitions).toInt
    var partitions: Vector[Vector[Int]] = Vector()

    // Add variables 0 - N-1 to partitions
    var lastIndex = 0
    for (i <- 1 until numberOfPartitions) {
      var partition: Vector[Int] = Vector()

      var j: Int = partitionSize * (i - 1)
      partition :+= j + 1
      partition :+= j + partitionSize

      partitions :+= partition
      lastIndex = i
    }

    partitions :+= Vector[Int](partitionSize * lastIndex + 1, (((partitionSize * lastIndex) + (partitionSize - 1)) + (lines - (partitionSize * numberOfPartitions))) + 1)

    partitions
  }


//val txtFile = sc.wholeTextFiles(s"/home/georgematlis/IdeaProjects/Scalable Processing of Dominance-Based Queries/Input/*")


/*
    val localSkylines = txtFile.map { case (_, content) =>
      val partition = content.split("\n").map(_.split(",").map(_.toDouble))
      println(partition)
      println("========")
      val p1 = partition.map(array => Point(array)).iterator
      // content.split("\n").map(_.split(",").map(_.toDouble)).map(array => Point(array)).iterator

      Skyline_Calculation.computeLocalSkyline(p1)
    }
     */

    /*
    // Assuming localSkylines: Iterator[Iterator[Point]]
    for (partitionIterator <- localSkylines) {
      for (point <- partitionIterator) {
        // Process each Point in the local skyline
        println(point)
      }
    }

     */




    //val r = localSkylines.mapPartitions(Skyline_Calculation.computeLocalSkyline)

    /*
    val localSkylines = txtFile.flatMap { case (filePath, content) =>
      content.split("\n").map(_.split(",")).map { line =>
        val coordinates = line.map(_.toDouble)
        Point(coordinates)
      }
    }.mapPartitions(Skyline_Calculation.computeLocalSkyline)

     */



def hashMapping(dPoint: Array[Double]): Int = {
    // Convert the d-dimensional point to a string for hashing
    val pointStr = dPoint.mkString(",")

    // Calculate the hash value
    val originalHash = MurmurHash3.stringHash(pointStr)

    originalHash.toInt
  }

def saveDominatedPointsToLocalFileSystem(dominatedPoints: ListBuffer[Point]): Unit = {

    // Assuming each partition writes to a separate file
    val partitionId = TaskContext.getPartitionId()
    val outputFilePath = new File(s"/home/georgematlis/IdeaProjects/Scalable Processing of Dominance-Based Queries/Input_Partitions/partition_$partitionId.txt")

    // Open a new PrintWriter for writing Dominated_Points
    val writer = new PrintWriter(outputFilePath)

    // Iterate over the ListBuffer and write each point to the file
    dominatedPoints.foreach { point =>
      // Convert point to a string representation as needed
      writer.println(point.dimensionValues.mkString(","))
    }

    // Close the writer
    writer.close()
  }

  def loadDominatedPointsFromLocalFileSystem(): List[Point] = {
    // Create an empty ListBuffer to store Dominated_Points
    val dominatedPoints = ListBuffer[Point]()

    // Assuming each partition wrote to a separate file
    val partitionId = TaskContext.getPartitionId()
    val inputFilePath = new File(s"/home/georgematlis/IdeaProjects/Scalable Processing of Dominance-Based Queries/Input_Partitions/partition_$partitionId.txt")

    // Read Dominated_Points from the file and add them to the ListBuffer
    val reader = new BufferedReader(new FileReader(inputFilePath))
    var line: String = null


    while ( {
      line = reader.readLine(); line != null
    }) {
      val point: Point = {
        // Parse the line and split dimension values
        val values = line.split(",").map(_.trim.toDouble)

        // Create a Point object using the parsed dimension values
        Point(dimensionValues = values)
      }

      dominatedPoints += point
    }

    // Close the reader
    reader.close()

    // Return the ListBuffer containing Dominated_Points
    dominatedPoints.toList
  }

// Function to compute dominance scores locally on each worker
  def computeLocalDominanceScores(iterator: Iterator[Point]): Iterator[Point] = {
    val points = iterator.toArray

    for {
      p1 <- points
      p2 <- points if p1 != p2
    } {
      if(dominates(p1, p2)) {
        p1.dominance_score += 1
      }
    }

    points.iterator
  }

// Assuming results is an RDD[Point]
    val combinedResults = results
      .map(point => (point, point.dominance_score)) // Convert Point to (Point, dominance_score) pair
      .aggregateByKey(0)(_ + _, _ + _) // Aggregate dominance scores by key (Point)

    // Extract the top dominating skyline points
    val topDominatingGlobalSkylinePoints = combinedResults
      .sortBy({ case (_, totalDominance) => totalDominance }, ascending = false)
      .map({ case (point, _) => point })

    //val topDominatingGlobalSkylinePoints = results.collect().distinct().sortBy(point => point.dominance_score, ascending = false)

    topDominatingGlobalSkylinePoints.foreach(println)